{
    "lora_rank": 4,
    "lora_init_scale": 0.01,
    "lora_modules": ".*SelfAttention|.*EncDecAttention|.*DenseReluDense",
    "lora_layers": "q|k|v|o|w.*",
    "trainable_param_names": ".*layer_norm.*|.*lora_[ab].*",
    "model_modifier": "lora",
    "lr": 3e-3,
    "num_steps": 1000
}