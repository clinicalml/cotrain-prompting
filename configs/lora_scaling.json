{
    "lora_scaling_rank": 1,
    "lora_rank": 0,
    "lora_init_scale": 0.0,
    "lora_modules": ".*SelfAttention|.*EncDecAttention|.*DenseReluDense",
    "lora_layers": "q|k|v|o|w.*",
    "trainable_param_names": ".*lora_[ab].*",
    "model_modifier": "lora",
    "lr": 3e-3,
    "num_steps": 1000
}